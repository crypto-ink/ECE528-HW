{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"q1a.ipynb","provenance":[{"file_id":"1ESk7wQLh8im6Y6qKGvJyFk2eXXBJBw4K","timestamp":1633544803406}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"cells":[{"cell_type":"code","metadata":{"id":"3yx1v4PWWDMY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hT0vqB4iRb_r"},"source":[" pip install -q tensorflow-model-optimization"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6L8IKX3cXp1"},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd \n","import math\n","import tempfile\n","import zipfile\n","import os\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import keras\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n","from keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report,confusion_matrix\n","from keras.callbacks import ReduceLROnPlateau\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BNJDHNLGdHNz"},"source":["# Modifying Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PLfcivr9LHIk","executionInfo":{"status":"ok","timestamp":1634090632233,"user_tz":360,"elapsed":32,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}},"outputId":"a50399ff-233c-4111-e2f1-4912102ae66b"},"source":["!ls \n","# !unzip sign.zip"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["american_sign_language.PNG  sample_data\t\t sign_mnist_train\n","amer_sign2.png\t\t    sign_mnist_test\t sign_mnist_train.csv\n","amer_sign3.png\t\t    sign_mnist_test.csv  sign.zip\n"]}]},{"cell_type":"code","metadata":{"id":"OJlbmVr9Q20B"},"source":["train_df = pd.read_csv(\"sign_mnist_train/sign_mnist_train.csv\")\n","test_df = pd.read_csv(\"sign_mnist_test/sign_mnist_test.csv\")\n","# print(test_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"038tTZ-PRROv"},"source":["test = pd.read_csv(\"sign_mnist_test/sign_mnist_test.csv\")\n","# print(test)\n","y = test['label']\n","# print(y.max())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"cOodPXDSRYni","executionInfo":{"status":"ok","timestamp":1634090635228,"user_tz":360,"elapsed":18,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}},"outputId":"509021d1-926b-496a-ba1a-9093d4cc53e2"},"source":["train_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>pixel1</th>\n","      <th>pixel2</th>\n","      <th>pixel3</th>\n","      <th>pixel4</th>\n","      <th>pixel5</th>\n","      <th>pixel6</th>\n","      <th>pixel7</th>\n","      <th>pixel8</th>\n","      <th>pixel9</th>\n","      <th>pixel10</th>\n","      <th>pixel11</th>\n","      <th>pixel12</th>\n","      <th>pixel13</th>\n","      <th>pixel14</th>\n","      <th>pixel15</th>\n","      <th>pixel16</th>\n","      <th>pixel17</th>\n","      <th>pixel18</th>\n","      <th>pixel19</th>\n","      <th>pixel20</th>\n","      <th>pixel21</th>\n","      <th>pixel22</th>\n","      <th>pixel23</th>\n","      <th>pixel24</th>\n","      <th>pixel25</th>\n","      <th>pixel26</th>\n","      <th>pixel27</th>\n","      <th>pixel28</th>\n","      <th>pixel29</th>\n","      <th>pixel30</th>\n","      <th>pixel31</th>\n","      <th>pixel32</th>\n","      <th>pixel33</th>\n","      <th>pixel34</th>\n","      <th>pixel35</th>\n","      <th>pixel36</th>\n","      <th>pixel37</th>\n","      <th>pixel38</th>\n","      <th>pixel39</th>\n","      <th>...</th>\n","      <th>pixel745</th>\n","      <th>pixel746</th>\n","      <th>pixel747</th>\n","      <th>pixel748</th>\n","      <th>pixel749</th>\n","      <th>pixel750</th>\n","      <th>pixel751</th>\n","      <th>pixel752</th>\n","      <th>pixel753</th>\n","      <th>pixel754</th>\n","      <th>pixel755</th>\n","      <th>pixel756</th>\n","      <th>pixel757</th>\n","      <th>pixel758</th>\n","      <th>pixel759</th>\n","      <th>pixel760</th>\n","      <th>pixel761</th>\n","      <th>pixel762</th>\n","      <th>pixel763</th>\n","      <th>pixel764</th>\n","      <th>pixel765</th>\n","      <th>pixel766</th>\n","      <th>pixel767</th>\n","      <th>pixel768</th>\n","      <th>pixel769</th>\n","      <th>pixel770</th>\n","      <th>pixel771</th>\n","      <th>pixel772</th>\n","      <th>pixel773</th>\n","      <th>pixel774</th>\n","      <th>pixel775</th>\n","      <th>pixel776</th>\n","      <th>pixel777</th>\n","      <th>pixel778</th>\n","      <th>pixel779</th>\n","      <th>pixel780</th>\n","      <th>pixel781</th>\n","      <th>pixel782</th>\n","      <th>pixel783</th>\n","      <th>pixel784</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>107</td>\n","      <td>118</td>\n","      <td>127</td>\n","      <td>134</td>\n","      <td>139</td>\n","      <td>143</td>\n","      <td>146</td>\n","      <td>150</td>\n","      <td>153</td>\n","      <td>156</td>\n","      <td>158</td>\n","      <td>160</td>\n","      <td>163</td>\n","      <td>165</td>\n","      <td>159</td>\n","      <td>166</td>\n","      <td>168</td>\n","      <td>170</td>\n","      <td>170</td>\n","      <td>171</td>\n","      <td>171</td>\n","      <td>171</td>\n","      <td>172</td>\n","      <td>171</td>\n","      <td>171</td>\n","      <td>170</td>\n","      <td>170</td>\n","      <td>169</td>\n","      <td>111</td>\n","      <td>121</td>\n","      <td>129</td>\n","      <td>135</td>\n","      <td>141</td>\n","      <td>144</td>\n","      <td>148</td>\n","      <td>151</td>\n","      <td>154</td>\n","      <td>157</td>\n","      <td>160</td>\n","      <td>...</td>\n","      <td>205</td>\n","      <td>206</td>\n","      <td>206</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>206</td>\n","      <td>206</td>\n","      <td>204</td>\n","      <td>205</td>\n","      <td>204</td>\n","      <td>203</td>\n","      <td>202</td>\n","      <td>142</td>\n","      <td>151</td>\n","      <td>160</td>\n","      <td>172</td>\n","      <td>196</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>190</td>\n","      <td>135</td>\n","      <td>96</td>\n","      <td>86</td>\n","      <td>77</td>\n","      <td>77</td>\n","      <td>79</td>\n","      <td>176</td>\n","      <td>205</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>206</td>\n","      <td>206</td>\n","      <td>206</td>\n","      <td>204</td>\n","      <td>203</td>\n","      <td>202</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6</td>\n","      <td>155</td>\n","      <td>157</td>\n","      <td>156</td>\n","      <td>156</td>\n","      <td>156</td>\n","      <td>157</td>\n","      <td>156</td>\n","      <td>158</td>\n","      <td>158</td>\n","      <td>157</td>\n","      <td>158</td>\n","      <td>156</td>\n","      <td>154</td>\n","      <td>154</td>\n","      <td>153</td>\n","      <td>152</td>\n","      <td>151</td>\n","      <td>149</td>\n","      <td>149</td>\n","      <td>148</td>\n","      <td>147</td>\n","      <td>146</td>\n","      <td>144</td>\n","      <td>142</td>\n","      <td>143</td>\n","      <td>138</td>\n","      <td>92</td>\n","      <td>108</td>\n","      <td>158</td>\n","      <td>159</td>\n","      <td>159</td>\n","      <td>159</td>\n","      <td>160</td>\n","      <td>160</td>\n","      <td>160</td>\n","      <td>160</td>\n","      <td>160</td>\n","      <td>160</td>\n","      <td>160</td>\n","      <td>...</td>\n","      <td>100</td>\n","      <td>78</td>\n","      <td>120</td>\n","      <td>157</td>\n","      <td>168</td>\n","      <td>107</td>\n","      <td>99</td>\n","      <td>121</td>\n","      <td>133</td>\n","      <td>97</td>\n","      <td>95</td>\n","      <td>120</td>\n","      <td>135</td>\n","      <td>116</td>\n","      <td>95</td>\n","      <td>79</td>\n","      <td>69</td>\n","      <td>86</td>\n","      <td>139</td>\n","      <td>173</td>\n","      <td>200</td>\n","      <td>185</td>\n","      <td>175</td>\n","      <td>198</td>\n","      <td>124</td>\n","      <td>118</td>\n","      <td>94</td>\n","      <td>140</td>\n","      <td>133</td>\n","      <td>84</td>\n","      <td>69</td>\n","      <td>149</td>\n","      <td>128</td>\n","      <td>87</td>\n","      <td>94</td>\n","      <td>163</td>\n","      <td>175</td>\n","      <td>103</td>\n","      <td>135</td>\n","      <td>149</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>187</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>187</td>\n","      <td>187</td>\n","      <td>186</td>\n","      <td>187</td>\n","      <td>188</td>\n","      <td>187</td>\n","      <td>186</td>\n","      <td>185</td>\n","      <td>185</td>\n","      <td>185</td>\n","      <td>184</td>\n","      <td>184</td>\n","      <td>184</td>\n","      <td>181</td>\n","      <td>181</td>\n","      <td>179</td>\n","      <td>179</td>\n","      <td>179</td>\n","      <td>178</td>\n","      <td>178</td>\n","      <td>109</td>\n","      <td>52</td>\n","      <td>66</td>\n","      <td>77</td>\n","      <td>83</td>\n","      <td>188</td>\n","      <td>189</td>\n","      <td>189</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>189</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>187</td>\n","      <td>...</td>\n","      <td>203</td>\n","      <td>204</td>\n","      <td>203</td>\n","      <td>201</td>\n","      <td>200</td>\n","      <td>200</td>\n","      <td>199</td>\n","      <td>198</td>\n","      <td>196</td>\n","      <td>195</td>\n","      <td>194</td>\n","      <td>193</td>\n","      <td>198</td>\n","      <td>166</td>\n","      <td>132</td>\n","      <td>114</td>\n","      <td>89</td>\n","      <td>74</td>\n","      <td>79</td>\n","      <td>77</td>\n","      <td>74</td>\n","      <td>78</td>\n","      <td>132</td>\n","      <td>188</td>\n","      <td>210</td>\n","      <td>209</td>\n","      <td>206</td>\n","      <td>205</td>\n","      <td>204</td>\n","      <td>203</td>\n","      <td>202</td>\n","      <td>201</td>\n","      <td>200</td>\n","      <td>199</td>\n","      <td>198</td>\n","      <td>199</td>\n","      <td>198</td>\n","      <td>195</td>\n","      <td>194</td>\n","      <td>195</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>211</td>\n","      <td>211</td>\n","      <td>212</td>\n","      <td>212</td>\n","      <td>211</td>\n","      <td>210</td>\n","      <td>211</td>\n","      <td>210</td>\n","      <td>210</td>\n","      <td>211</td>\n","      <td>209</td>\n","      <td>207</td>\n","      <td>208</td>\n","      <td>207</td>\n","      <td>206</td>\n","      <td>203</td>\n","      <td>202</td>\n","      <td>201</td>\n","      <td>200</td>\n","      <td>198</td>\n","      <td>197</td>\n","      <td>195</td>\n","      <td>192</td>\n","      <td>197</td>\n","      <td>171</td>\n","      <td>51</td>\n","      <td>52</td>\n","      <td>54</td>\n","      <td>212</td>\n","      <td>213</td>\n","      <td>215</td>\n","      <td>215</td>\n","      <td>212</td>\n","      <td>212</td>\n","      <td>213</td>\n","      <td>212</td>\n","      <td>212</td>\n","      <td>211</td>\n","      <td>211</td>\n","      <td>...</td>\n","      <td>247</td>\n","      <td>242</td>\n","      <td>233</td>\n","      <td>231</td>\n","      <td>230</td>\n","      <td>229</td>\n","      <td>227</td>\n","      <td>225</td>\n","      <td>223</td>\n","      <td>221</td>\n","      <td>220</td>\n","      <td>216</td>\n","      <td>58</td>\n","      <td>51</td>\n","      <td>49</td>\n","      <td>50</td>\n","      <td>57</td>\n","      <td>60</td>\n","      <td>17</td>\n","      <td>15</td>\n","      <td>18</td>\n","      <td>17</td>\n","      <td>19</td>\n","      <td>1</td>\n","      <td>159</td>\n","      <td>255</td>\n","      <td>237</td>\n","      <td>239</td>\n","      <td>237</td>\n","      <td>236</td>\n","      <td>235</td>\n","      <td>234</td>\n","      <td>233</td>\n","      <td>231</td>\n","      <td>230</td>\n","      <td>226</td>\n","      <td>225</td>\n","      <td>222</td>\n","      <td>229</td>\n","      <td>163</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13</td>\n","      <td>164</td>\n","      <td>167</td>\n","      <td>170</td>\n","      <td>172</td>\n","      <td>176</td>\n","      <td>179</td>\n","      <td>180</td>\n","      <td>184</td>\n","      <td>185</td>\n","      <td>186</td>\n","      <td>188</td>\n","      <td>189</td>\n","      <td>189</td>\n","      <td>190</td>\n","      <td>191</td>\n","      <td>189</td>\n","      <td>190</td>\n","      <td>190</td>\n","      <td>187</td>\n","      <td>190</td>\n","      <td>192</td>\n","      <td>193</td>\n","      <td>191</td>\n","      <td>191</td>\n","      <td>192</td>\n","      <td>192</td>\n","      <td>194</td>\n","      <td>194</td>\n","      <td>166</td>\n","      <td>169</td>\n","      <td>172</td>\n","      <td>174</td>\n","      <td>177</td>\n","      <td>180</td>\n","      <td>182</td>\n","      <td>185</td>\n","      <td>186</td>\n","      <td>187</td>\n","      <td>190</td>\n","      <td>...</td>\n","      <td>90</td>\n","      <td>77</td>\n","      <td>88</td>\n","      <td>117</td>\n","      <td>123</td>\n","      <td>127</td>\n","      <td>129</td>\n","      <td>134</td>\n","      <td>145</td>\n","      <td>152</td>\n","      <td>156</td>\n","      <td>179</td>\n","      <td>105</td>\n","      <td>106</td>\n","      <td>105</td>\n","      <td>104</td>\n","      <td>104</td>\n","      <td>104</td>\n","      <td>175</td>\n","      <td>199</td>\n","      <td>178</td>\n","      <td>152</td>\n","      <td>136</td>\n","      <td>130</td>\n","      <td>136</td>\n","      <td>150</td>\n","      <td>118</td>\n","      <td>92</td>\n","      <td>85</td>\n","      <td>76</td>\n","      <td>92</td>\n","      <td>105</td>\n","      <td>105</td>\n","      <td>108</td>\n","      <td>133</td>\n","      <td>163</td>\n","      <td>157</td>\n","      <td>163</td>\n","      <td>164</td>\n","      <td>179</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 785 columns</p>\n","</div>"],"text/plain":["   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n","0      3     107     118     127  ...       206       204       203       202\n","1      6     155     157     156  ...       175       103       135       149\n","2      2     187     188     188  ...       198       195       194       195\n","3      2     211     211     212  ...       225       222       229       163\n","4     13     164     167     170  ...       157       163       164       179\n","\n","[5 rows x 785 columns]"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"Qxr5bmk6VVJ4"},"source":["train_labels = train_df['label']\n","test_labels = test_df['label']\n","del train_df['label']\n","del test_df['label']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dZhzHrq2VtXB"},"source":["train_images = train_df.values\n","test_images = test_df.values\n","# Normalize the data\n","\n","# print(train_images.shape)\n","# print(test_images.shape)\n","\n","train_images = train_images / 255\n","test_images = test_images / 255\n","train_images = train_images.reshape(-1,28,28,1)\n","test_images = test_images.reshape(-1,28,28,1)\n","# print(train_images.shape)\n","# print(test_images.shape)\n","\n","# print(train_df)\n","# print(train_images)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lmA-E9iPdAn4"},"source":["# Creating CNN model"]},{"cell_type":"code","metadata":{"id":"2YoH_AbIX8QC"},"source":["\n","#setup CNN model\n","def setup_model():\n","  model = keras.Sequential([\n","      # tf.keras.layers.Reshape(input_shape=(28*28,), target_shape(28,28,1)),\n","\n","      keras.layers.Conv2D(kernel_size = 3, filters = 100, activation = 'relu', padding = 'same', input_shape=(28,28,1)), \n","      tf.keras.layers.BatchNormalization(center = True, scale = False),\n","      tf.keras.layers.Activation('relu'),\n","\n","      keras.layers.Conv2D(kernel_size = 3, filters = 70, activation = 'relu', padding = 'same', strides = 1),\n","      tf.keras.layers.BatchNormalization(center = True, scale = False),\n","      tf.keras.layers.Activation('relu'),\n","      tf.keras.layers.MaxPool2D((2,2) , strides = 1 , padding = 'same'),\n","      keras.layers.Dropout(0.25),\n","\n","      keras.layers.Conv2D(kernel_size = 3, filters = 32, activation = 'relu', padding = 'same', strides = 1),\n","      tf.keras.layers.BatchNormalization(center = True, scale = False),\n","      tf.keras.layers.Activation('relu'),\n","\n","\n","\n","      keras.layers.Flatten(),\n","\n","      keras.layers.Dense(500, use_bias = False),\n","      tf.keras.layers.BatchNormalization(center = True, scale = False),\n","      tf.keras.layers.Activation('relu'),\n","      keras.layers.Dropout(0.20),\n","\n","      keras.layers.Dense(100, activation = 'relu'),\n","      keras.layers.Dropout(0.15),\n","\n","      keras.layers.Dense(25, activation = 'softmax')\n","      ])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJo79vrkYApA"},"source":["#lr decay function\n","def lr_decay(epoch):\n","  return 0.01 * math.pow(0.6, epoch)\n","\n","#lr schedule callback\n","lr_decay_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay,)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MDpn3GJeGKgw"},"source":["def train_model(model):\n","  model.compile(optimizer='adam',\n","          loss='sparse_categorical_crossentropy',\n","          metrics=['accuracy'])\n","  model.summary()\n","  model.fit(train_images, train_labels, epochs=20, callbacks = [lr_decay_callback])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2tfCDzhG_fs"},"source":["def save_model_weights(model):\n","  _, pretrained_weights = tempfile.mkstemp('.h5')\n","  model.save_weights(pretrained_weights)\n","  return pretrained_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BOaLuGq5HDtj"},"source":["def setup_pretrained_weights():\n","  model= setup_model()\n","  model = train_model(model)\n","  pretrained_weights = save_model_weights(model)\n","  return pretrained_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VRuRnKoRHF7O"},"source":["def save_model_file(model):\n","  _, keras_file = tempfile.mkstemp('.h5') \n","  model.save(keras_file, include_optimizer=False)\n","  return keras_file"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fc3_EUBzHK0H"},"source":["def get_gzipped_model_size(model):\n","  # It returns the size of the gzipped model in bytes.\n","  import os\n","  import zipfile\n","\n","  keras_file = save_model_file(model)\n","\n","  _, zipped_file = tempfile.mkstemp('.zip')\n","  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n","    f.write(keras_file)\n","  return os.path.getsize(zipped_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RLnWslQzVMbm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634090778575,"user_tz":360,"elapsed":142966,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}},"outputId":"45bf57be-6f25-462f-dfae-65925e12eb19"},"source":["#define the model\n","model = setup_model()\n","# Train the model\n","model = train_model(model)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_9 (Conv2D)            (None, 28, 28, 100)       1000      \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 28, 28, 100)       300       \n","_________________________________________________________________\n","activation_12 (Activation)   (None, 28, 28, 100)       0         \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 28, 28, 70)        63070     \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 28, 28, 70)        210       \n","_________________________________________________________________\n","activation_13 (Activation)   (None, 28, 28, 70)        0         \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 28, 28, 70)        0         \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 28, 28, 70)        0         \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 28, 28, 32)        20192     \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 28, 28, 32)        96        \n","_________________________________________________________________\n","activation_14 (Activation)   (None, 28, 28, 32)        0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 25088)             0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 500)               12544000  \n","_________________________________________________________________\n","batch_normalization_15 (Batc (None, 500)               1500      \n","_________________________________________________________________\n","activation_15 (Activation)   (None, 500)               0         \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 500)               0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 100)               50100     \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 100)               0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 25)                2525      \n","=================================================================\n","Total params: 12,682,993\n","Trainable params: 12,681,589\n","Non-trainable params: 1,404\n","_________________________________________________________________\n","Epoch 1/20\n","858/858 [==============================] - 7s 8ms/step - loss: 0.3627 - accuracy: 0.8894\n","Epoch 2/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0212 - accuracy: 0.9930\n","Epoch 3/20\n","858/858 [==============================] - 6s 8ms/step - loss: 0.0098 - accuracy: 0.9969\n","Epoch 4/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0036 - accuracy: 0.9988\n","Epoch 5/20\n","858/858 [==============================] - 6s 8ms/step - loss: 0.0028 - accuracy: 0.9991\n","Epoch 6/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0014 - accuracy: 0.9997\n","Epoch 7/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 8/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0013 - accuracy: 0.9995\n","Epoch 9/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0010 - accuracy: 0.9998\n","Epoch 10/20\n","858/858 [==============================] - 6s 7ms/step - loss: 5.3545e-04 - accuracy: 0.9999\n","Epoch 11/20\n","858/858 [==============================] - 6s 7ms/step - loss: 8.3162e-04 - accuracy: 0.9997\n","Epoch 12/20\n","858/858 [==============================] - 6s 7ms/step - loss: 9.1066e-04 - accuracy: 0.9997\n","Epoch 13/20\n","858/858 [==============================] - 6s 8ms/step - loss: 8.2846e-04 - accuracy: 0.9997\n","Epoch 14/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0010 - accuracy: 0.9998\n","Epoch 15/20\n","858/858 [==============================] - 6s 7ms/step - loss: 7.7715e-04 - accuracy: 0.9998\n","Epoch 16/20\n","858/858 [==============================] - 6s 7ms/step - loss: 5.8643e-04 - accuracy: 0.9997\n","Epoch 17/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0013 - accuracy: 0.9995\n","Epoch 18/20\n","858/858 [==============================] - 6s 7ms/step - loss: 6.5209e-04 - accuracy: 0.9998\n","Epoch 19/20\n","858/858 [==============================] - 6s 7ms/step - loss: 6.0533e-04 - accuracy: 0.9999\n","Epoch 20/20\n","858/858 [==============================] - 6s 7ms/step - loss: 9.3773e-04 - accuracy: 0.9997\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"06IhgGBaWMtP","executionInfo":{"status":"ok","timestamp":1634090779412,"user_tz":360,"elapsed":845,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}},"outputId":"8994d40b-bf9d-4bef-9128-0b8d6a527656"},"source":["# Evaluate the base model\n","_, baseline_model_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n","\n","print('Baseline test accuracy:', baseline_model_accuracy)\n","\n","_, keras_file = tempfile.mkstemp('.h5')\n","print('Saving model to: ', keras_file)\n","tf.keras.models.save_model(model, keras_file, include_optimizer=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline test accuracy: 0.9380925893783569\n","Saving model to:  /tmp/tmpxq7ta9l_.h5\n"]}]}]}