{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"q1d.ipynb","provenance":[{"file_id":"1ESk7wQLh8im6Y6qKGvJyFk2eXXBJBw4K","timestamp":1633544803406}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"cells":[{"cell_type":"code","metadata":{"id":"hT0vqB4iRb_r","executionInfo":{"status":"ok","timestamp":1634145687911,"user_tz":360,"elapsed":2664,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}}},"source":[" pip install -q tensorflow-model-optimization"],"execution_count":75,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6L8IKX3cXp1","executionInfo":{"status":"ok","timestamp":1634145687911,"user_tz":360,"elapsed":16,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd \n","import math\n","import tempfile\n","import zipfile\n","import os\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import keras\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n","from keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report,confusion_matrix\n","from keras.callbacks import ReduceLROnPlateau\n"],"execution_count":76,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BNJDHNLGdHNz"},"source":["# Modifying Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PLfcivr9LHIk","executionInfo":{"status":"ok","timestamp":1634145687912,"user_tz":360,"elapsed":15,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}},"outputId":"bfe2f160-0d15-4715-e3b0-7ac8264c36eb"},"source":["!ls \n","# !unzip sign.zip"],"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["american_sign_language.PNG  sample_data\t\t sign_mnist_train\n","amer_sign2.png\t\t    sign_mnist_test\t sign_mnist_train.csv\n","amer_sign3.png\t\t    sign_mnist_test.csv  sign.zip\n"]}]},{"cell_type":"code","metadata":{"id":"OJlbmVr9Q20B","executionInfo":{"status":"ok","timestamp":1634145691801,"user_tz":360,"elapsed":3896,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}}},"source":["train_df = pd.read_csv(\"sign_mnist_train/sign_mnist_train.csv\")\n","test_df = pd.read_csv(\"sign_mnist_test/sign_mnist_test.csv\")\n","# print(test_df)"],"execution_count":78,"outputs":[]},{"cell_type":"code","metadata":{"id":"038tTZ-PRROv","executionInfo":{"status":"ok","timestamp":1634145691802,"user_tz":360,"elapsed":37,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}}},"source":["test = pd.read_csv(\"sign_mnist_test/sign_mnist_test.csv\")\n","# print(test)\n","y = test['label']\n","# print(y.max())"],"execution_count":79,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"cOodPXDSRYni","executionInfo":{"status":"ok","timestamp":1634145691804,"user_tz":360,"elapsed":37,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}},"outputId":"9308c83d-4a3b-4397-dc7b-3e0c48e9c36f"},"source":["train_df.head()"],"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>pixel1</th>\n","      <th>pixel2</th>\n","      <th>pixel3</th>\n","      <th>pixel4</th>\n","      <th>pixel5</th>\n","      <th>pixel6</th>\n","      <th>pixel7</th>\n","      <th>pixel8</th>\n","      <th>pixel9</th>\n","      <th>pixel10</th>\n","      <th>pixel11</th>\n","      <th>pixel12</th>\n","      <th>pixel13</th>\n","      <th>pixel14</th>\n","      <th>pixel15</th>\n","      <th>pixel16</th>\n","      <th>pixel17</th>\n","      <th>pixel18</th>\n","      <th>pixel19</th>\n","      <th>pixel20</th>\n","      <th>pixel21</th>\n","      <th>pixel22</th>\n","      <th>pixel23</th>\n","      <th>pixel24</th>\n","      <th>pixel25</th>\n","      <th>pixel26</th>\n","      <th>pixel27</th>\n","      <th>pixel28</th>\n","      <th>pixel29</th>\n","      <th>pixel30</th>\n","      <th>pixel31</th>\n","      <th>pixel32</th>\n","      <th>pixel33</th>\n","      <th>pixel34</th>\n","      <th>pixel35</th>\n","      <th>pixel36</th>\n","      <th>pixel37</th>\n","      <th>pixel38</th>\n","      <th>pixel39</th>\n","      <th>...</th>\n","      <th>pixel745</th>\n","      <th>pixel746</th>\n","      <th>pixel747</th>\n","      <th>pixel748</th>\n","      <th>pixel749</th>\n","      <th>pixel750</th>\n","      <th>pixel751</th>\n","      <th>pixel752</th>\n","      <th>pixel753</th>\n","      <th>pixel754</th>\n","      <th>pixel755</th>\n","      <th>pixel756</th>\n","      <th>pixel757</th>\n","      <th>pixel758</th>\n","      <th>pixel759</th>\n","      <th>pixel760</th>\n","      <th>pixel761</th>\n","      <th>pixel762</th>\n","      <th>pixel763</th>\n","      <th>pixel764</th>\n","      <th>pixel765</th>\n","      <th>pixel766</th>\n","      <th>pixel767</th>\n","      <th>pixel768</th>\n","      <th>pixel769</th>\n","      <th>pixel770</th>\n","      <th>pixel771</th>\n","      <th>pixel772</th>\n","      <th>pixel773</th>\n","      <th>pixel774</th>\n","      <th>pixel775</th>\n","      <th>pixel776</th>\n","      <th>pixel777</th>\n","      <th>pixel778</th>\n","      <th>pixel779</th>\n","      <th>pixel780</th>\n","      <th>pixel781</th>\n","      <th>pixel782</th>\n","      <th>pixel783</th>\n","      <th>pixel784</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>107</td>\n","      <td>118</td>\n","      <td>127</td>\n","      <td>134</td>\n","      <td>139</td>\n","      <td>143</td>\n","      <td>146</td>\n","      <td>150</td>\n","      <td>153</td>\n","      <td>156</td>\n","      <td>158</td>\n","      <td>160</td>\n","      <td>163</td>\n","      <td>165</td>\n","      <td>159</td>\n","      <td>166</td>\n","      <td>168</td>\n","      <td>170</td>\n","      <td>170</td>\n","      <td>171</td>\n","      <td>171</td>\n","      <td>171</td>\n","      <td>172</td>\n","      <td>171</td>\n","      <td>171</td>\n","      <td>170</td>\n","      <td>170</td>\n","      <td>169</td>\n","      <td>111</td>\n","      <td>121</td>\n","      <td>129</td>\n","      <td>135</td>\n","      <td>141</td>\n","      <td>144</td>\n","      <td>148</td>\n","      <td>151</td>\n","      <td>154</td>\n","      <td>157</td>\n","      <td>160</td>\n","      <td>...</td>\n","      <td>205</td>\n","      <td>206</td>\n","      <td>206</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>206</td>\n","      <td>206</td>\n","      <td>204</td>\n","      <td>205</td>\n","      <td>204</td>\n","      <td>203</td>\n","      <td>202</td>\n","      <td>142</td>\n","      <td>151</td>\n","      <td>160</td>\n","      <td>172</td>\n","      <td>196</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>190</td>\n","      <td>135</td>\n","      <td>96</td>\n","      <td>86</td>\n","      <td>77</td>\n","      <td>77</td>\n","      <td>79</td>\n","      <td>176</td>\n","      <td>205</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>206</td>\n","      <td>206</td>\n","      <td>206</td>\n","      <td>204</td>\n","      <td>203</td>\n","      <td>202</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6</td>\n","      <td>155</td>\n","      <td>157</td>\n","      <td>156</td>\n","      <td>156</td>\n","      <td>156</td>\n","      <td>157</td>\n","      <td>156</td>\n","      <td>158</td>\n","      <td>158</td>\n","      <td>157</td>\n","      <td>158</td>\n","      <td>156</td>\n","      <td>154</td>\n","      <td>154</td>\n","      <td>153</td>\n","      <td>152</td>\n","      <td>151</td>\n","      <td>149</td>\n","      <td>149</td>\n","      <td>148</td>\n","      <td>147</td>\n","      <td>146</td>\n","      <td>144</td>\n","      <td>142</td>\n","      <td>143</td>\n","      <td>138</td>\n","      <td>92</td>\n","      <td>108</td>\n","      <td>158</td>\n","      <td>159</td>\n","      <td>159</td>\n","      <td>159</td>\n","      <td>160</td>\n","      <td>160</td>\n","      <td>160</td>\n","      <td>160</td>\n","      <td>160</td>\n","      <td>160</td>\n","      <td>160</td>\n","      <td>...</td>\n","      <td>100</td>\n","      <td>78</td>\n","      <td>120</td>\n","      <td>157</td>\n","      <td>168</td>\n","      <td>107</td>\n","      <td>99</td>\n","      <td>121</td>\n","      <td>133</td>\n","      <td>97</td>\n","      <td>95</td>\n","      <td>120</td>\n","      <td>135</td>\n","      <td>116</td>\n","      <td>95</td>\n","      <td>79</td>\n","      <td>69</td>\n","      <td>86</td>\n","      <td>139</td>\n","      <td>173</td>\n","      <td>200</td>\n","      <td>185</td>\n","      <td>175</td>\n","      <td>198</td>\n","      <td>124</td>\n","      <td>118</td>\n","      <td>94</td>\n","      <td>140</td>\n","      <td>133</td>\n","      <td>84</td>\n","      <td>69</td>\n","      <td>149</td>\n","      <td>128</td>\n","      <td>87</td>\n","      <td>94</td>\n","      <td>163</td>\n","      <td>175</td>\n","      <td>103</td>\n","      <td>135</td>\n","      <td>149</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>187</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>187</td>\n","      <td>187</td>\n","      <td>186</td>\n","      <td>187</td>\n","      <td>188</td>\n","      <td>187</td>\n","      <td>186</td>\n","      <td>185</td>\n","      <td>185</td>\n","      <td>185</td>\n","      <td>184</td>\n","      <td>184</td>\n","      <td>184</td>\n","      <td>181</td>\n","      <td>181</td>\n","      <td>179</td>\n","      <td>179</td>\n","      <td>179</td>\n","      <td>178</td>\n","      <td>178</td>\n","      <td>109</td>\n","      <td>52</td>\n","      <td>66</td>\n","      <td>77</td>\n","      <td>83</td>\n","      <td>188</td>\n","      <td>189</td>\n","      <td>189</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>189</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>187</td>\n","      <td>...</td>\n","      <td>203</td>\n","      <td>204</td>\n","      <td>203</td>\n","      <td>201</td>\n","      <td>200</td>\n","      <td>200</td>\n","      <td>199</td>\n","      <td>198</td>\n","      <td>196</td>\n","      <td>195</td>\n","      <td>194</td>\n","      <td>193</td>\n","      <td>198</td>\n","      <td>166</td>\n","      <td>132</td>\n","      <td>114</td>\n","      <td>89</td>\n","      <td>74</td>\n","      <td>79</td>\n","      <td>77</td>\n","      <td>74</td>\n","      <td>78</td>\n","      <td>132</td>\n","      <td>188</td>\n","      <td>210</td>\n","      <td>209</td>\n","      <td>206</td>\n","      <td>205</td>\n","      <td>204</td>\n","      <td>203</td>\n","      <td>202</td>\n","      <td>201</td>\n","      <td>200</td>\n","      <td>199</td>\n","      <td>198</td>\n","      <td>199</td>\n","      <td>198</td>\n","      <td>195</td>\n","      <td>194</td>\n","      <td>195</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>211</td>\n","      <td>211</td>\n","      <td>212</td>\n","      <td>212</td>\n","      <td>211</td>\n","      <td>210</td>\n","      <td>211</td>\n","      <td>210</td>\n","      <td>210</td>\n","      <td>211</td>\n","      <td>209</td>\n","      <td>207</td>\n","      <td>208</td>\n","      <td>207</td>\n","      <td>206</td>\n","      <td>203</td>\n","      <td>202</td>\n","      <td>201</td>\n","      <td>200</td>\n","      <td>198</td>\n","      <td>197</td>\n","      <td>195</td>\n","      <td>192</td>\n","      <td>197</td>\n","      <td>171</td>\n","      <td>51</td>\n","      <td>52</td>\n","      <td>54</td>\n","      <td>212</td>\n","      <td>213</td>\n","      <td>215</td>\n","      <td>215</td>\n","      <td>212</td>\n","      <td>212</td>\n","      <td>213</td>\n","      <td>212</td>\n","      <td>212</td>\n","      <td>211</td>\n","      <td>211</td>\n","      <td>...</td>\n","      <td>247</td>\n","      <td>242</td>\n","      <td>233</td>\n","      <td>231</td>\n","      <td>230</td>\n","      <td>229</td>\n","      <td>227</td>\n","      <td>225</td>\n","      <td>223</td>\n","      <td>221</td>\n","      <td>220</td>\n","      <td>216</td>\n","      <td>58</td>\n","      <td>51</td>\n","      <td>49</td>\n","      <td>50</td>\n","      <td>57</td>\n","      <td>60</td>\n","      <td>17</td>\n","      <td>15</td>\n","      <td>18</td>\n","      <td>17</td>\n","      <td>19</td>\n","      <td>1</td>\n","      <td>159</td>\n","      <td>255</td>\n","      <td>237</td>\n","      <td>239</td>\n","      <td>237</td>\n","      <td>236</td>\n","      <td>235</td>\n","      <td>234</td>\n","      <td>233</td>\n","      <td>231</td>\n","      <td>230</td>\n","      <td>226</td>\n","      <td>225</td>\n","      <td>222</td>\n","      <td>229</td>\n","      <td>163</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13</td>\n","      <td>164</td>\n","      <td>167</td>\n","      <td>170</td>\n","      <td>172</td>\n","      <td>176</td>\n","      <td>179</td>\n","      <td>180</td>\n","      <td>184</td>\n","      <td>185</td>\n","      <td>186</td>\n","      <td>188</td>\n","      <td>189</td>\n","      <td>189</td>\n","      <td>190</td>\n","      <td>191</td>\n","      <td>189</td>\n","      <td>190</td>\n","      <td>190</td>\n","      <td>187</td>\n","      <td>190</td>\n","      <td>192</td>\n","      <td>193</td>\n","      <td>191</td>\n","      <td>191</td>\n","      <td>192</td>\n","      <td>192</td>\n","      <td>194</td>\n","      <td>194</td>\n","      <td>166</td>\n","      <td>169</td>\n","      <td>172</td>\n","      <td>174</td>\n","      <td>177</td>\n","      <td>180</td>\n","      <td>182</td>\n","      <td>185</td>\n","      <td>186</td>\n","      <td>187</td>\n","      <td>190</td>\n","      <td>...</td>\n","      <td>90</td>\n","      <td>77</td>\n","      <td>88</td>\n","      <td>117</td>\n","      <td>123</td>\n","      <td>127</td>\n","      <td>129</td>\n","      <td>134</td>\n","      <td>145</td>\n","      <td>152</td>\n","      <td>156</td>\n","      <td>179</td>\n","      <td>105</td>\n","      <td>106</td>\n","      <td>105</td>\n","      <td>104</td>\n","      <td>104</td>\n","      <td>104</td>\n","      <td>175</td>\n","      <td>199</td>\n","      <td>178</td>\n","      <td>152</td>\n","      <td>136</td>\n","      <td>130</td>\n","      <td>136</td>\n","      <td>150</td>\n","      <td>118</td>\n","      <td>92</td>\n","      <td>85</td>\n","      <td>76</td>\n","      <td>92</td>\n","      <td>105</td>\n","      <td>105</td>\n","      <td>108</td>\n","      <td>133</td>\n","      <td>163</td>\n","      <td>157</td>\n","      <td>163</td>\n","      <td>164</td>\n","      <td>179</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 785 columns</p>\n","</div>"],"text/plain":["   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n","0      3     107     118     127  ...       206       204       203       202\n","1      6     155     157     156  ...       175       103       135       149\n","2      2     187     188     188  ...       198       195       194       195\n","3      2     211     211     212  ...       225       222       229       163\n","4     13     164     167     170  ...       157       163       164       179\n","\n","[5 rows x 785 columns]"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","metadata":{"id":"Qxr5bmk6VVJ4","executionInfo":{"status":"ok","timestamp":1634145691805,"user_tz":360,"elapsed":23,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}}},"source":["train_labels = train_df['label']\n","test_labels = test_df['label']\n","del train_df['label']\n","del test_df['label']"],"execution_count":81,"outputs":[]},{"cell_type":"code","metadata":{"id":"dZhzHrq2VtXB","executionInfo":{"status":"ok","timestamp":1634145691805,"user_tz":360,"elapsed":22,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}}},"source":["train_images = train_df.values\n","test_images = test_df.values\n","# Normalize the data\n","\n","# print(train_images.shape)\n","# print(test_images.shape)\n","\n","train_images = train_images / 255\n","test_images = test_images / 255\n","train_images = train_images.reshape(-1,28,28,1)\n","test_images = test_images.reshape(-1,28,28,1)\n","# print(train_images.shape)\n","# print(test_images.shape)\n","\n","# print(train_df)\n","# print(train_images)"],"execution_count":82,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lmA-E9iPdAn4"},"source":["# Creating CNN model"]},{"cell_type":"code","metadata":{"id":"2YoH_AbIX8QC","executionInfo":{"status":"ok","timestamp":1634145691806,"user_tz":360,"elapsed":22,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}}},"source":["\n","#setup CNN model\n","def setup_model():\n","  model = keras.Sequential([\n","      # tf.keras.layers.Reshape(input_shape=(28*28,), target_shape(28,28,1)),\n","\n","      keras.layers.Conv2D(kernel_size = 3, filters = 100, activation = 'relu', padding = 'same', input_shape=(28,28,1)), \n","      tf.keras.layers.BatchNormalization(center = True, scale = False),\n","      tf.keras.layers.Activation('relu'),\n","\n","      keras.layers.Conv2D(kernel_size = 3, filters = 70, activation = 'relu', padding = 'same', strides = 1),\n","      tf.keras.layers.BatchNormalization(center = True, scale = False),\n","      tf.keras.layers.Activation('relu'),\n","      tf.keras.layers.MaxPool2D((2,2) , strides = 1 , padding = 'same'),\n","      keras.layers.Dropout(0.25),\n","\n","      keras.layers.Conv2D(kernel_size = 3, filters = 32, activation = 'relu', padding = 'same', strides = 1),\n","      tf.keras.layers.BatchNormalization(center = True, scale = False),\n","      tf.keras.layers.Activation('relu'),\n","\n","\n","\n","      keras.layers.Flatten(),\n","\n","      keras.layers.Dense(500, use_bias = False),\n","      tf.keras.layers.BatchNormalization(center = True, scale = False),\n","      tf.keras.layers.Activation('relu'),\n","      keras.layers.Dropout(0.20),\n","\n","      keras.layers.Dense(100, activation = 'relu'),\n","      keras.layers.Dropout(0.15),\n","\n","      keras.layers.Dense(25, activation = 'softmax')\n","      ])\n","  return model"],"execution_count":83,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJo79vrkYApA","executionInfo":{"status":"ok","timestamp":1634145691806,"user_tz":360,"elapsed":22,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}}},"source":["#lr decay function\n","def lr_decay(epoch):\n","  return 0.01 * math.pow(0.6, epoch)\n","\n","#lr schedule callback\n","lr_decay_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay,)"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"id":"QOYzNF27XbuQ","executionInfo":{"status":"ok","timestamp":1634145691807,"user_tz":360,"elapsed":22,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}}},"source":["def setup_pretrained_weights():\n","  model= setup_model()\n","\n","  model.compile(\n","      loss=tf.keras.losses.categorical_crossentropy,\n","      optimizer='adam',\n","      metrics=['accuracy']\n","  )\n","\n","  model.fit(train_images, train_labels)\n","\n","  _, pretrained_weights = tempfile.mkstemp('.tf')\n","\n","  model.save_weights(pretrained_weights)\n","\n","  return pretrained_weights"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJPXsvAuXnFw","executionInfo":{"status":"ok","timestamp":1634145691807,"user_tz":360,"elapsed":21,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}}},"source":["def setup_pretrained_model():\n","  model = setup_model()\n","  pretrained_weights = setup_pretrained_weights()\n","  model.load_weights(pretrained_weights)\n","  return model"],"execution_count":86,"outputs":[]},{"cell_type":"code","metadata":{"id":"MDpn3GJeGKgw","executionInfo":{"status":"ok","timestamp":1634145691808,"user_tz":360,"elapsed":22,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}}},"source":["def train_model(model):\n","  model.compile(optimizer='adam',\n","          loss='sparse_categorical_crossentropy',\n","          metrics=['accuracy'])\n","  model.summary()\n","  model.fit(train_images, train_labels, epochs=20, callbacks = [lr_decay_callback])\n","  return model"],"execution_count":87,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NAwsJnhnYoNA","executionInfo":{"status":"ok","timestamp":1634148068829,"user_tz":360,"elapsed":125731,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}},"outputId":"35e2f33a-ef5c-407f-bcf5-667e8ab46eb9"},"source":["#define the model\n","model = setup_model()\n","# Train the model\n","model = train_model(model)"],"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_57 (Conv2D)           (None, 28, 28, 100)       1000      \n","_________________________________________________________________\n","batch_normalization_76 (Batc (None, 28, 28, 100)       300       \n","_________________________________________________________________\n","activation_76 (Activation)   (None, 28, 28, 100)       0         \n","_________________________________________________________________\n","conv2d_58 (Conv2D)           (None, 28, 28, 70)        63070     \n","_________________________________________________________________\n","batch_normalization_77 (Batc (None, 28, 28, 70)        210       \n","_________________________________________________________________\n","activation_77 (Activation)   (None, 28, 28, 70)        0         \n","_________________________________________________________________\n","max_pooling2d_19 (MaxPooling (None, 28, 28, 70)        0         \n","_________________________________________________________________\n","dropout_57 (Dropout)         (None, 28, 28, 70)        0         \n","_________________________________________________________________\n","conv2d_59 (Conv2D)           (None, 28, 28, 32)        20192     \n","_________________________________________________________________\n","batch_normalization_78 (Batc (None, 28, 28, 32)        96        \n","_________________________________________________________________\n","activation_78 (Activation)   (None, 28, 28, 32)        0         \n","_________________________________________________________________\n","flatten_19 (Flatten)         (None, 25088)             0         \n","_________________________________________________________________\n","dense_57 (Dense)             (None, 500)               12544000  \n","_________________________________________________________________\n","batch_normalization_79 (Batc (None, 500)               1500      \n","_________________________________________________________________\n","activation_79 (Activation)   (None, 500)               0         \n","_________________________________________________________________\n","dropout_58 (Dropout)         (None, 500)               0         \n","_________________________________________________________________\n","dense_58 (Dense)             (None, 100)               50100     \n","_________________________________________________________________\n","dropout_59 (Dropout)         (None, 100)               0         \n","_________________________________________________________________\n","dense_59 (Dense)             (None, 25)                2525      \n","=================================================================\n","Total params: 12,682,993\n","Trainable params: 12,681,589\n","Non-trainable params: 1,404\n","_________________________________________________________________\n","Epoch 1/20\n","858/858 [==============================] - 7s 7ms/step - loss: 0.3879 - accuracy: 0.8781\n","Epoch 2/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0352 - accuracy: 0.9892\n","Epoch 3/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0129 - accuracy: 0.9961\n","Epoch 4/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0034 - accuracy: 0.9988\n","Epoch 5/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0034 - accuracy: 0.9990\n","Epoch 6/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0017 - accuracy: 0.9996\n","Epoch 7/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 8/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 9/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0011 - accuracy: 0.9998\n","Epoch 10/20\n","858/858 [==============================] - 6s 7ms/step - loss: 6.9784e-04 - accuracy: 0.9998\n","Epoch 11/20\n","858/858 [==============================] - 6s 7ms/step - loss: 9.0010e-04 - accuracy: 0.9998\n","Epoch 12/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0011 - accuracy: 0.9995\n","Epoch 13/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0010 - accuracy: 0.9995\n","Epoch 14/20\n","858/858 [==============================] - 6s 7ms/step - loss: 8.8622e-04 - accuracy: 0.9998\n","Epoch 15/20\n","858/858 [==============================] - 6s 7ms/step - loss: 7.0092e-04 - accuracy: 0.9999\n","Epoch 16/20\n","858/858 [==============================] - 6s 7ms/step - loss: 7.8673e-04 - accuracy: 0.9997\n","Epoch 17/20\n","858/858 [==============================] - 6s 7ms/step - loss: 0.0011 - accuracy: 0.9997\n","Epoch 18/20\n","858/858 [==============================] - 6s 7ms/step - loss: 5.1375e-04 - accuracy: 0.9999\n","Epoch 19/20\n","858/858 [==============================] - 6s 7ms/step - loss: 6.9400e-04 - accuracy: 0.9998\n","Epoch 20/20\n","858/858 [==============================] - 6s 7ms/step - loss: 8.0627e-04 - accuracy: 0.9998\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KukUtzeIqBNe","executionInfo":{"status":"ok","timestamp":1634148069731,"user_tz":360,"elapsed":927,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}},"outputId":"eef5cff4-a0b0-43d5-bad3-7cccc5c58342"},"source":["# Evaluate the base model\n","_, baseline_model_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n","\n","print('Baseline test accuracy:', baseline_model_accuracy)\n","\n","_, keras_file = tempfile.mkstemp('.h5')\n","print('Saving model to: ', keras_file)\n","tf.keras.models.save_model(model, keras_file, include_optimizer=False)"],"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline test accuracy: 0.9456218481063843\n","Saving model to:  /tmp/tmpc3tbv7yo.h5\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ix2b2hRvXs-p"},"source":["# Define quantization aware model"]},{"cell_type":"code","metadata":{"id":"PT8MwXgeXseL","executionInfo":{"status":"ok","timestamp":1634148070360,"user_tz":360,"elapsed":145,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}}},"source":["import tensorflow_model_optimization as tfmot\n","\n","base_model = setup_model()\n","# base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n"],"execution_count":115,"outputs":[]},{"cell_type":"code","metadata":{"id":"a9oBsv6-bWKM","executionInfo":{"status":"ok","timestamp":1634148070361,"user_tz":360,"elapsed":8,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}}},"source":["# Helper function uses `quantize_annotate_layer` to annotate that only the \n","# Dense layers should be quantized.\n","def apply_quantization_to_dense(layer):\n","  if (isinstance(layer, tf.keras.layers.Dense) \n","  or isinstance(layer, tf.keras.layers.Conv2D)\n","  or isinstance(layer, tf.keras.layers.Activation)\n","  or isinstance(layer, tf.keras.layers.MaxPool2D)\n","  or isinstance(layer, tf.keras.layers.Dropout)\n","  or isinstance(layer, tf.keras.layers.Flatten)):\n","    return tfmot.quantization.keras.quantize_annotate_layer(layer)\n","  return layer"],"execution_count":116,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pQECc3QHbWPu","executionInfo":{"status":"ok","timestamp":1634148071045,"user_tz":360,"elapsed":690,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}},"outputId":"a8b4ed94-ce72-4a4b-92ba-154d587ba92c"},"source":["# Use `tf.keras.models.clone_model` to apply `apply_quantization_to_dense` \n","# to the layers of the model.\n","annotated_model = tf.keras.models.clone_model(\n","    base_model,\n","    clone_function=apply_quantization_to_dense,\n",")\n","\n","# Now that the Dense layers are annotated,\n","# `quantize_apply` actually makes the model quantization aware.\n","quant_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)\n","\n","# `quantize_model` requires a recompile.\n","quant_aware_model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","quant_aware_model.summary()"],"execution_count":117,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_20\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","quantize_layer_8 (QuantizeLa (None, 28, 28, 1)         3         \n","_________________________________________________________________\n","quant_conv2d_60 (QuantizeWra (None, 28, 28, 100)       1203      \n","_________________________________________________________________\n","batch_normalization_80 (Batc (None, 28, 28, 100)       300       \n","_________________________________________________________________\n","quant_activation_80 (Quantiz (None, 28, 28, 100)       3         \n","_________________________________________________________________\n","quant_conv2d_61 (QuantizeWra (None, 28, 28, 70)        63213     \n","_________________________________________________________________\n","batch_normalization_81 (Batc (None, 28, 28, 70)        210       \n","_________________________________________________________________\n","quant_activation_81 (Quantiz (None, 28, 28, 70)        3         \n","_________________________________________________________________\n","quant_max_pooling2d_20 (Quan (None, 28, 28, 70)        1         \n","_________________________________________________________________\n","quant_dropout_60 (QuantizeWr (None, 28, 28, 70)        1         \n","_________________________________________________________________\n","quant_conv2d_62 (QuantizeWra (None, 28, 28, 32)        20259     \n","_________________________________________________________________\n","batch_normalization_82 (Batc (None, 28, 28, 32)        96        \n","_________________________________________________________________\n","quant_activation_82 (Quantiz (None, 28, 28, 32)        3         \n","_________________________________________________________________\n","quant_flatten_20 (QuantizeWr (None, 25088)             1         \n","_________________________________________________________________\n","quant_dense_60 (QuantizeWrap (None, 500)               12544005  \n","_________________________________________________________________\n","batch_normalization_83 (Batc (None, 500)               1500      \n","_________________________________________________________________\n","quant_activation_83 (Quantiz (None, 500)               3         \n","_________________________________________________________________\n","quant_dropout_61 (QuantizeWr (None, 500)               1         \n","_________________________________________________________________\n","quant_dense_61 (QuantizeWrap (None, 100)               50105     \n","_________________________________________________________________\n","quant_dropout_62 (QuantizeWr (None, 100)               1         \n","_________________________________________________________________\n","quant_dense_62 (QuantizeWrap (None, 25)                2530      \n","=================================================================\n","Total params: 12,683,441\n","Trainable params: 12,681,589\n","Non-trainable params: 1,852\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGPgI2JTeHTC","executionInfo":{"status":"ok","timestamp":1634148497548,"user_tz":360,"elapsed":212607,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}},"outputId":"294cf7d9-220a-4790-c7f3-2085560dd7ba"},"source":["train_images_subset = train_images[0:1000] # out of 60000\n","train_labels_subset = train_labels[0:1000]\n","\n","quant_aware_model.fit(train_images, train_labels,\n","                  batch_size=500, epochs=50,callbacks = [lr_decay_callback], validation_split=0.1)"],"execution_count":121,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","50/50 [==============================] - 4s 86ms/step - loss: 0.0752 - accuracy: 0.9762 - val_loss: 14.1882 - val_accuracy: 0.2152\n","Epoch 2/50\n","50/50 [==============================] - 4s 84ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 1.2736 - val_accuracy: 0.7356\n","Epoch 3/50\n","50/50 [==============================] - 4s 84ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0396 - val_accuracy: 0.9865\n","Epoch 4/50\n","50/50 [==============================] - 4s 84ms/step - loss: 6.3431e-04 - accuracy: 0.9998 - val_loss: 1.7808e-05 - val_accuracy: 1.0000\n","Epoch 5/50\n","50/50 [==============================] - 4s 85ms/step - loss: 5.8030e-04 - accuracy: 0.9999 - val_loss: 5.6684e-06 - val_accuracy: 1.0000\n","Epoch 6/50\n","50/50 [==============================] - 4s 85ms/step - loss: 4.9110e-04 - accuracy: 0.9999 - val_loss: 4.9479e-06 - val_accuracy: 1.0000\n","Epoch 7/50\n","50/50 [==============================] - 4s 85ms/step - loss: 4.1444e-04 - accuracy: 1.0000 - val_loss: 3.9403e-06 - val_accuracy: 1.0000\n","Epoch 8/50\n","50/50 [==============================] - 4s 85ms/step - loss: 4.3886e-04 - accuracy: 0.9999 - val_loss: 3.1879e-06 - val_accuracy: 1.0000\n","Epoch 9/50\n","50/50 [==============================] - 4s 85ms/step - loss: 3.9450e-04 - accuracy: 1.0000 - val_loss: 2.9368e-06 - val_accuracy: 1.0000\n","Epoch 10/50\n","50/50 [==============================] - 4s 84ms/step - loss: 4.9503e-04 - accuracy: 0.9999 - val_loss: 2.8656e-06 - val_accuracy: 1.0000\n","Epoch 11/50\n","50/50 [==============================] - 4s 85ms/step - loss: 3.2426e-04 - accuracy: 1.0000 - val_loss: 2.8361e-06 - val_accuracy: 1.0000\n","Epoch 12/50\n","50/50 [==============================] - 4s 84ms/step - loss: 3.4234e-04 - accuracy: 1.0000 - val_loss: 2.7001e-06 - val_accuracy: 1.0000\n","Epoch 13/50\n","50/50 [==============================] - 4s 85ms/step - loss: 3.4196e-04 - accuracy: 1.0000 - val_loss: 2.7180e-06 - val_accuracy: 1.0000\n","Epoch 14/50\n","50/50 [==============================] - 4s 84ms/step - loss: 3.2828e-04 - accuracy: 1.0000 - val_loss: 2.4480e-06 - val_accuracy: 1.0000\n","Epoch 15/50\n","50/50 [==============================] - 4s 85ms/step - loss: 6.0384e-04 - accuracy: 0.9999 - val_loss: 2.5235e-06 - val_accuracy: 1.0000\n","Epoch 16/50\n","50/50 [==============================] - 4s 85ms/step - loss: 3.7313e-04 - accuracy: 0.9999 - val_loss: 2.7168e-06 - val_accuracy: 1.0000\n","Epoch 17/50\n","50/50 [==============================] - 4s 84ms/step - loss: 3.9106e-04 - accuracy: 1.0000 - val_loss: 2.7199e-06 - val_accuracy: 1.0000\n","Epoch 18/50\n","50/50 [==============================] - 4s 84ms/step - loss: 3.7916e-04 - accuracy: 0.9999 - val_loss: 2.7859e-06 - val_accuracy: 1.0000\n","Epoch 19/50\n","50/50 [==============================] - 4s 85ms/step - loss: 3.2407e-04 - accuracy: 1.0000 - val_loss: 2.7905e-06 - val_accuracy: 1.0000\n","Epoch 20/50\n","50/50 [==============================] - 4s 85ms/step - loss: 6.0226e-04 - accuracy: 0.9999 - val_loss: 2.6827e-06 - val_accuracy: 1.0000\n","Epoch 21/50\n","50/50 [==============================] - 4s 85ms/step - loss: 4.8314e-04 - accuracy: 1.0000 - val_loss: 2.6753e-06 - val_accuracy: 1.0000\n","Epoch 22/50\n","50/50 [==============================] - 4s 84ms/step - loss: 6.2409e-04 - accuracy: 0.9999 - val_loss: 2.7074e-06 - val_accuracy: 1.0000\n","Epoch 23/50\n","50/50 [==============================] - 4s 85ms/step - loss: 3.7042e-04 - accuracy: 1.0000 - val_loss: 2.7787e-06 - val_accuracy: 1.0000\n","Epoch 24/50\n","50/50 [==============================] - 4s 85ms/step - loss: 4.6828e-04 - accuracy: 0.9999 - val_loss: 2.7327e-06 - val_accuracy: 1.0000\n","Epoch 25/50\n","50/50 [==============================] - 4s 85ms/step - loss: 3.4362e-04 - accuracy: 0.9999 - val_loss: 2.8211e-06 - val_accuracy: 1.0000\n","Epoch 26/50\n","50/50 [==============================] - 4s 85ms/step - loss: 3.5910e-04 - accuracy: 1.0000 - val_loss: 2.5976e-06 - val_accuracy: 1.0000\n","Epoch 27/50\n","50/50 [==============================] - 4s 85ms/step - loss: 4.3541e-04 - accuracy: 0.9999 - val_loss: 2.8432e-06 - val_accuracy: 1.0000\n","Epoch 28/50\n","50/50 [==============================] - 4s 85ms/step - loss: 5.4879e-04 - accuracy: 0.9999 - val_loss: 2.6402e-06 - val_accuracy: 1.0000\n","Epoch 29/50\n","50/50 [==============================] - 4s 85ms/step - loss: 5.4115e-04 - accuracy: 0.9999 - val_loss: 2.8003e-06 - val_accuracy: 1.0000\n","Epoch 30/50\n","50/50 [==============================] - 4s 85ms/step - loss: 4.5721e-04 - accuracy: 0.9999 - val_loss: 2.8487e-06 - val_accuracy: 1.0000\n","Epoch 31/50\n","50/50 [==============================] - 4s 85ms/step - loss: 6.6618e-04 - accuracy: 0.9998 - val_loss: 2.7406e-06 - val_accuracy: 1.0000\n","Epoch 32/50\n","50/50 [==============================] - 4s 85ms/step - loss: 3.8719e-04 - accuracy: 1.0000 - val_loss: 2.7269e-06 - val_accuracy: 1.0000\n","Epoch 33/50\n","50/50 [==============================] - 4s 85ms/step - loss: 6.0232e-04 - accuracy: 0.9998 - val_loss: 2.6956e-06 - val_accuracy: 1.0000\n","Epoch 34/50\n","50/50 [==============================] - 4s 85ms/step - loss: 4.3801e-04 - accuracy: 0.9999 - val_loss: 2.7384e-06 - val_accuracy: 1.0000\n","Epoch 35/50\n","50/50 [==============================] - 4s 85ms/step - loss: 3.5352e-04 - accuracy: 1.0000 - val_loss: 2.7798e-06 - val_accuracy: 1.0000\n","Epoch 36/50\n","50/50 [==============================] - 4s 85ms/step - loss: 4.7378e-04 - accuracy: 0.9999 - val_loss: 2.6646e-06 - val_accuracy: 1.0000\n","Epoch 37/50\n","50/50 [==============================] - 4s 85ms/step - loss: 6.8328e-04 - accuracy: 0.9999 - val_loss: 2.6703e-06 - val_accuracy: 1.0000\n","Epoch 38/50\n","50/50 [==============================] - 4s 85ms/step - loss: 4.0203e-04 - accuracy: 1.0000 - val_loss: 2.9168e-06 - val_accuracy: 1.0000\n","Epoch 39/50\n","50/50 [==============================] - 4s 85ms/step - loss: 6.5115e-04 - accuracy: 0.9998 - val_loss: 2.7035e-06 - val_accuracy: 1.0000\n","Epoch 40/50\n","50/50 [==============================] - 4s 85ms/step - loss: 5.0691e-04 - accuracy: 0.9999 - val_loss: 2.7156e-06 - val_accuracy: 1.0000\n","Epoch 41/50\n","50/50 [==============================] - 4s 84ms/step - loss: 4.1690e-04 - accuracy: 0.9999 - val_loss: 2.5501e-06 - val_accuracy: 1.0000\n","Epoch 42/50\n","50/50 [==============================] - 4s 85ms/step - loss: 4.8586e-04 - accuracy: 0.9999 - val_loss: 2.7227e-06 - val_accuracy: 1.0000\n","Epoch 43/50\n","50/50 [==============================] - 4s 85ms/step - loss: 4.5156e-04 - accuracy: 1.0000 - val_loss: 2.7949e-06 - val_accuracy: 1.0000\n","Epoch 44/50\n","50/50 [==============================] - 4s 85ms/step - loss: 5.8167e-04 - accuracy: 0.9999 - val_loss: 2.6231e-06 - val_accuracy: 1.0000\n","Epoch 45/50\n","50/50 [==============================] - 4s 85ms/step - loss: 4.2458e-04 - accuracy: 1.0000 - val_loss: 2.6995e-06 - val_accuracy: 1.0000\n","Epoch 46/50\n","50/50 [==============================] - 4s 85ms/step - loss: 4.4784e-04 - accuracy: 1.0000 - val_loss: 2.8184e-06 - val_accuracy: 1.0000\n","Epoch 47/50\n","50/50 [==============================] - 4s 86ms/step - loss: 3.4063e-04 - accuracy: 0.9999 - val_loss: 2.7532e-06 - val_accuracy: 1.0000\n","Epoch 48/50\n","50/50 [==============================] - 4s 85ms/step - loss: 4.6072e-04 - accuracy: 0.9999 - val_loss: 2.6208e-06 - val_accuracy: 1.0000\n","Epoch 49/50\n","50/50 [==============================] - 4s 85ms/step - loss: 3.4746e-04 - accuracy: 1.0000 - val_loss: 2.6826e-06 - val_accuracy: 1.0000\n","Epoch 50/50\n","50/50 [==============================] - 4s 85ms/step - loss: 4.1197e-04 - accuracy: 1.0000 - val_loss: 2.8253e-06 - val_accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc008325d10>"]},"metadata":{},"execution_count":121}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EjdC4Zize32K","executionInfo":{"status":"ok","timestamp":1634148499115,"user_tz":360,"elapsed":1586,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}},"outputId":"09eb5760-884a-47ff-e508-835135918992"},"source":["_, baseline_model_accuracy = model.evaluate(\n","    test_images, test_labels, verbose=0)\n","\n","_, quant_aware_model_accuracy = quant_aware_model.evaluate(\n","   test_images, test_labels, verbose=0)\n","\n","print('Baseline test accuracy:', baseline_model_accuracy)\n","print('Quant test accuracy:', quant_aware_model_accuracy)"],"execution_count":122,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline test accuracy: 0.9456218481063843\n","Quant test accuracy: 0.9344673752784729\n"]}]},{"cell_type":"markdown","metadata":{"id":"0Jt4DFyNgzTC"},"source":["# Quantized Tflite model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNZVoESngyN3","executionInfo":{"status":"ok","timestamp":1634148506558,"user_tz":360,"elapsed":7445,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}},"outputId":"08f6553e-8c35-4116-d81d-0acf5292d8a7"},"source":["# Convert model to dynamic range quantization\n","converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","quantized_tflite_model = converter.convert()\n","\n","# Save the model as quantized tflite file.\n","with open('sign_mnist_quant_aware_training.tflite', 'wb') as f:\n","  f.write(quantized_tflite_model)"],"execution_count":123,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, activation_80_layer_call_and_return_conditional_losses, activation_80_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses while saving (showing 5 of 70). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /tmp/tmpel4hiw8z/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /tmp/tmpel4hiw8z/assets\n"]}]},{"cell_type":"code","metadata":{"id":"UU38aQLXhGVf","executionInfo":{"status":"ok","timestamp":1634150222745,"user_tz":360,"elapsed":116,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}}},"source":["def evaluate_model(interpreter):\n","  input_index = interpreter.get_input_details()[0][\"index\"]\n","  output_index = interpreter.get_output_details()[0][\"index\"]\n","\n","  # Run predictions on every image in the \"test\" dataset.\n","  prediction_digits = []\n","  for i, test_image in enumerate(test_images):\n","    if i % 1000 == 0:\n","      print('Evaluated on {n} results so far.'.format(n=i))\n","    # Pre-processing: add batch dimension and convert to float32 to match with\n","    # the model's input data format.\n","    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n","    interpreter.set_tensor(input_index, test_image)\n","\n","    # Run inference.\n","    interpreter.invoke()\n","\n","    # Post-processing: remove batch dimension and find the digit with highest\n","    # probability.\n","    output = interpreter.tensor(output_index)\n","    digit = np.argmax(output()[0])\n","    prediction_digits.append(digit)\n","\n","  print('\\n')\n","  # Compare prediction results with ground truth labels to calculate accuracy.\n","  prediction_digits = np.array(prediction_digits)\n","  accuracy = (prediction_digits == test_labels).mean()\n","  return accuracy"],"execution_count":127,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yiOdWonlhKw7","executionInfo":{"status":"ok","timestamp":1634151647356,"user_tz":360,"elapsed":1422648,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}},"outputId":"9a8bf5be-d7dd-4599-c316-8028edff567c"},"source":["interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n","interpreter.allocate_tensors()\n","\n","test_accuracy = evaluate_model(interpreter)\n","\n","print('Quant TFLite test_accuracy:', test_accuracy)\n","print('Quant TF test accuracy:', quant_aware_model_accuracy)"],"execution_count":128,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluated on 0 results so far.\n","Evaluated on 1000 results so far.\n","Evaluated on 2000 results so far.\n","Evaluated on 3000 results so far.\n","Evaluated on 4000 results so far.\n","Evaluated on 5000 results so far.\n","Evaluated on 6000 results so far.\n","Evaluated on 7000 results so far.\n","\n","\n","Quant TFLite test_accuracy: 0.9348856664807585\n","Quant TF test accuracy: 0.9344673752784729\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h0wT7nVLqyWp","executionInfo":{"status":"ok","timestamp":1634152704617,"user_tz":360,"elapsed":388,"user":{"displayName":"Pablo Corona","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14507682739370897590"}},"outputId":"c5e072b3-0c90-4a58-bb97-8a56b7cfe3e6"},"source":["# !ls -s sign_mnist.tflite\n","!ls -s sign_mnist_quant_aware_training.tflite"],"execution_count":129,"outputs":[{"output_type":"stream","name":"stdout","text":["12408 sign_mnist_quant_aware_training.tflite\n"]}]}]}